{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: `Candidate` Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "\n",
    "# TO USE A DATABASE OTHER THAN SQLITE, USE THIS LINE\n",
    "# Note that this is necessary for parallel execution amongst other things...\n",
    "os.environ['SNORKELDB'] = 'postgres:///semparse_spouse'\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "Spouse = candidate_subclass('Spouse', ['person1', 'person2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import Ngrams, CandidateExtractor\n",
    "from snorkel.matchers import PersonMatcher\n",
    "\n",
    "ngrams         = Ngrams(n_max=3)\n",
    "person_matcher = PersonMatcher(longest_match_only=True)\n",
    "cand_extractor = CandidateExtractor(Spouse, \n",
    "                                    [ngrams, ngrams], [person_matcher, person_matcher],\n",
    "                                    symmetric_relations=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def number_of_people(sentence):\n",
    "    active_sequence = False\n",
    "    count = 0\n",
    "    for tag in sentence.ner_tags:\n",
    "        if tag == 'PERSON' and not active_sequence:\n",
    "            active_sequence = True\n",
    "            count += 1\n",
    "        elif tag != 'PERSON' and active_sequence:\n",
    "            active_sequence = False\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Documents: 72\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Document\n",
    "docs = session.query(Document).order_by(Document.name).all()\n",
    "print \"Total Documents: {}\".format(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "labeled_docs = set()\n",
    "with open(os.environ['SNORKELHOME'] + '/tutorials/spouse/data/articles_dev.tsv') as tsvin:\n",
    "    reader = csv.reader(tsvin, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        doc = row[0]\n",
    "        labeled_docs.add(doc)\n",
    "print \"Labeled documents: {}\".format(len(labeled_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import Document\n",
    "import random\n",
    "\n",
    "train_sents = set()\n",
    "dev_sents = set()\n",
    "for doc in docs:\n",
    "    if doc.name in labeled_docs:\n",
    "        sents = dev_sents\n",
    "    else:\n",
    "        sents = train_sents\n",
    "    for s in doc.sentences:\n",
    "        if number_of_people(s) < 5:\n",
    "            sents.add(s)\n",
    "\n",
    "# filtered_sents = 0\n",
    "# train_sents = set()\n",
    "# dev_sents   = set()\n",
    "# test_sents  = set()\n",
    "# unlabeled_sents = set()\n",
    "# splits = [0, 1, 0] # train, dev, test\n",
    "# for i, doc in enumerate(docs):\n",
    "#     for s in doc.sentences:\n",
    "#         if number_of_people(s) < 5:\n",
    "#             if doc.name in labeled_docs:\n",
    "#                 r = random.random()\n",
    "#                 if r < splits[0]:\n",
    "#                     train_sents.add(s)\n",
    "#                 elif r < (splits[0] + splits[1]):\n",
    "#                     dev_sents.add(s)\n",
    "#                 else:\n",
    "#                     test_sents.add(s)\n",
    "#             else:\n",
    "#                 unlabeled_sents.add(s)\n",
    "#         else:\n",
    "#             filtered_sents += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Train sentences: %d\" % len(train_sents)\n",
    "print \"Dev sentences: %d\" % len(dev_sents)\n",
    "# print \"Test sentences: %d\" % len(test_sents)\n",
    "# print \"Unlabeled sentences: %d\" % len(unlabeled_sents)\n",
    "# print \"Filtered sentences: %d\" % filtered_sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the `CandidateExtractor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the `CandidateExtractor` by calling extract with the contexts to extract from, a name for the `CandidateSet` that will contain the results, and the current session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, sents in enumerate([train_sents, dev_sents]): #, test_sents, unlabeled_sents]):\n",
    "    %time cand_extractor.apply(sents, split=i, parallelism=1, clear=True)\n",
    "    print \"Number of candidates: %d\" % session.query(Spouse).filter(Spouse.split == i).count()\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print os.environ['SNORKELDB']\n",
    "print len(session.query(Spouse).filter(Spouse.split == 1).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we specified that these `Candidates` belong to the training set by specifying `split=0`; recall that we're referring to train / dev / test as splits 0 / 1 / 2.\n",
    "\n",
    "Note also that again, we could have specified a `parallelism` parameter to execute in parralel, if we had a non-SQLite database set up. Now let's get the candidates we just extracted:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the `Viewer` to inspect candidates\n",
    "\n",
    "Next, we'll use the `Viewer` class--here, specifically, the `SentenceNgramViewer`--to inspect the data.\n",
    "\n",
    "It is important to note, our goal here is to **maximize the recall of true candidates** extracted, **not** to extract _only_ the correct candidates. Learning to distinguish true candidates from false candidates is covered in Tutorial 4.\n",
    "\n",
    "First, we instantiate the `Viewer` object, which groups the input `Candidate` objects by `Sentence`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from snorkel.viewer import SentenceNgramViewer\n",
    "\n",
    "dev_cands = session.query(Spouse).filter(Spouse.split == 1).all()\n",
    "sv = SentenceNgramViewer(dev_cands[:300], session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we render the `Viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 'CI' not in os.environ:\n",
    "    print unicode(sv.get_selected())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, in Part 3, we will annotate some candidates with labels so that we can evaluate performance."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {
    "71c24f10bba34d25a279c242d6f74319": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
