{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part VI: Natural Language Supervision\n",
    "\n",
    "We will compare the performance of:\n",
    "\n",
    "(a) traditional supervision - positive and negative labels on examples\n",
    "\n",
    "(b) natural language supervision - explanations converted into LFs, which are then denoised and applied to unlabeled data to create a much larger but noisy training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "# TO USE A DATABASE OTHER THAN SQLITE, USE THIS LINE\n",
    "# Note that this is necessary for parallel execution amongst other things...\n",
    "os.environ['SNORKELDB'] = 'postgres:///semparse'\n",
    "\n",
    "import numpy as np\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat our definition of the `Spouse` `Candidate` subclass from Parts II and III."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "Spouse = candidate_subclass('Spouse', ['person1', 'person2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import FeatureAnnotator\n",
    "featurizer = FeatureAnnotator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F_train = featurizer.load_matrix(session, split=0)\n",
    "F_dev   = featurizer.load_matrix(session, split=1)\n",
    "F_unlabeled   = featurizer.load_matrix(session, split=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "L_gold_train = load_gold_labels(session, annotator_name='gold', split=0)\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Natural Language Supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<function LF_distant_supervision at 0x11a1e0aa0>,\n",
      " <function LF_distant_supervision_last_names at 0x11a1e0b18>,\n",
      " <function LF_husband_wife at 0x11a1e05f0>,\n",
      " <function LF_husband_wife_left_window at 0x11a1e0668>,\n",
      " <function LF_same_last_name at 0x11a1e06e0>,\n",
      " <function LF_no_spouse_in_sentence at 0x11a1e0758>,\n",
      " <function LF_and_married at 0x11a1e07d0>,\n",
      " <function LF_familial_relationship at 0x11a1e0848>,\n",
      " <function LF_family_left_window at 0x11a1e08c0>,\n",
      " <function LF_other_relationship at 0x11a1e0938>]\n"
     ]
    }
   ],
   "source": [
    "# PYTHON LFs\n",
    "from pprint import pprint\n",
    "from python_lfs import get_python_lfs\n",
    "\n",
    "python_lfs = get_python_lfs()\n",
    "pprint(python_lfs)\n",
    "# LFs = python_lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NL LFs\n",
    "spouse = ['wife', 'husband', 'ex-wife', 'ex-husband']\n",
    "family = ['father', 'mother', 'sister', 'brother', 'son', 'daughter',\n",
    "          'grandfather', 'grandmother', 'uncle', 'aunt', 'cousin']\n",
    "family = family + [f + '-in-law' for f in family]\n",
    "coworker = ['boss', 'employee', 'secretary', 'co-worker']\n",
    "\n",
    "user_lists = {'spouse': spouse,\n",
    "              'family': family,\n",
    "              'coworker': coworker}\n",
    "\n",
    "explanations = [\n",
    "    \"Label false because the number of words between arg 1 and arg 2 is larger than 10\",\n",
    "    \"Label false because there is a person between arg 1 and arg 2\",\n",
    "    \"Label true because there is at least one spouse word in the words between arg 1 and arg 2\",\n",
    "    \"Label true because there is at least one spouse word within two words to the left of arg 1 or arg 2\",\n",
    "    \"Label false because there are no spouse words in the sentence\",\n",
    "    \"Label true because the word 'and' is between arg 1 and arg 2 and 'married' is to the right of arg 2\",\n",
    "    \"Label false because there is at least one family word between arg 1 and arg 2\",\n",
    "    \"Label false because there is at least one family word within two words to the left of arg 1 or arg 2\",\n",
    "    \"Label false because there is at least one coworker word between arg 1 and arg 2\",\n",
    "    \"Label false because arg 1 is identical to arg 2\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created grammar with 148 rules\n",
      "13 LFs created from 10 explanations\n"
     ]
    }
   ],
   "source": [
    "from snorkel.semantic.parser import SemanticParser\n",
    "\n",
    "sp = SemanticParser()\n",
    "LFs = sp.parse(explanations, user_lists=user_lists, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function exp0_parse0 at 0x11b636c80>\n",
      "<function exp1_parse0 at 0x11c191410>\n",
      "<function exp2_parse0 at 0x11c19e9b0>\n",
      "<function exp3_parse0 at 0x11c1b3b90>\n",
      "<function exp4_parse0 at 0x11c1b66e0>\n",
      "<function exp5_parse0 at 0x11c1cc500>\n",
      "<function exp5_parse1 at 0x11c1ccde8>\n",
      "<function exp6_parse0 at 0x11ca18938>\n",
      "<function exp6_parse1 at 0x11ca24230>\n",
      "<function exp7_parse0 at 0x11ca37e60>\n",
      "<function exp8_parse0 at 0x11ca3e410>\n",
      "<function exp8_parse1 at 0x11ca40758>\n",
      "<function exp9_parse0 at 0x11ca40c80>\n"
     ]
    }
   ],
   "source": [
    "for lf in LFs:\n",
    "    print lf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate one LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lf = LFs[4]\n",
    "# print lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# labeled = []\n",
    "# for c in session.query(Spouse).filter(Spouse.split == 3).all():\n",
    "#     try:\n",
    "#         if lf(c) != 0:\n",
    "#             labeled.append(c)\n",
    "#     except:\n",
    "#         pass\n",
    "# print \"Number labeled:\", len(labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from snorkel.viewer import SentenceNgramViewer\n",
    "\n",
    "# sv = SentenceNgramViewer(labeled[:300], session)\n",
    "# sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from snorkel.lf_helpers import test_LF\n",
    "# tp, fp, tn, fn = test_LF(session, lf, split=0, annotator_name='gold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply all LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import LabelAnnotator\n",
    "labeler = LabelAnnotator(f=LFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "CPU times: user 1min 1s, sys: 1.35 s, total: 1min 3s\n",
      "Wall time: 1min 15s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<4780x13 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 8734 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1701)\n",
    "%time L_unlabeled = labeler.apply(split=3)\n",
    "L_unlabeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>exp0_parse0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.393515</td>\n",
       "      <td>0.389749</td>\n",
       "      <td>0.023431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp1_parse0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.258787</td>\n",
       "      <td>0.257113</td>\n",
       "      <td>0.018619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp2_parse0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.036820</td>\n",
       "      <td>0.029916</td>\n",
       "      <td>0.023640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp3_parse0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.020711</td>\n",
       "      <td>0.017992</td>\n",
       "      <td>0.011925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp4_parse0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.929289</td>\n",
       "      <td>0.467782</td>\n",
       "      <td>0.002510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp5_parse0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.002720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp5_parse1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.002720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp6_parse0</th>\n",
       "      <td>7</td>\n",
       "      <td>0.051255</td>\n",
       "      <td>0.051255</td>\n",
       "      <td>0.007531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp6_parse1</th>\n",
       "      <td>8</td>\n",
       "      <td>0.051255</td>\n",
       "      <td>0.051255</td>\n",
       "      <td>0.007531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp7_parse0</th>\n",
       "      <td>9</td>\n",
       "      <td>0.027406</td>\n",
       "      <td>0.026778</td>\n",
       "      <td>0.001674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp8_parse0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.003138</td>\n",
       "      <td>0.003138</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp8_parse1</th>\n",
       "      <td>11</td>\n",
       "      <td>0.003138</td>\n",
       "      <td>0.003138</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp9_parse0</th>\n",
       "      <td>12</td>\n",
       "      <td>0.046025</td>\n",
       "      <td>0.045816</td>\n",
       "      <td>0.000418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              j  Coverage  Overlaps  Conflicts\n",
       "exp0_parse0   0  0.393515  0.389749   0.023431\n",
       "exp1_parse0   1  0.258787  0.257113   0.018619\n",
       "exp2_parse0   2  0.036820  0.029916   0.023640\n",
       "exp3_parse0   3  0.020711  0.017992   0.011925\n",
       "exp4_parse0   4  0.929289  0.467782   0.002510\n",
       "exp5_parse0   5  0.002929  0.002929   0.002720\n",
       "exp5_parse1   6  0.002929  0.002929   0.002720\n",
       "exp6_parse0   7  0.051255  0.051255   0.007531\n",
       "exp6_parse1   8  0.051255  0.051255   0.007531\n",
       "exp7_parse0   9  0.027406  0.026778   0.001674\n",
       "exp8_parse0  10  0.003138  0.003138   0.000000\n",
       "exp8_parse1  11  0.003138  0.003138   0.000000\n",
       "exp9_parse0  12  0.046025  0.045816   0.000418"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_unlabeled.lf_stats(session, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "\n",
    "gen_model = GenerativeModel()\n",
    "gen_model.train(L_unlabeled, epochs=500, decay=0.95, step_size=0.1/L_unlabeled.shape[0], reg_param=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_marginals = gen_model.marginals(L_unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEACAYAAAC6d6FnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkhplAEhSo/4P9hvzgzNuo6QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11cb67e90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(train_marginals, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "L_dev = labeler.apply_existing(split=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.417\n",
      "Neg. class accuracy: 0.978\n",
      "Precision            0.417\n",
      "Recall               0.417\n",
      "F1                   0.417\n",
      "----------------------------------------\n",
      "TP: 5 | FP: 7 | TN: 315 | FN: 7\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp, fp, tn, fn = gen_model.score(session, L_dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>Empirical Acc.</th>\n",
       "      <th>Learned Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>exp0_parse0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.398204</td>\n",
       "      <td>0.395210</td>\n",
       "      <td>0.029940</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>127</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.653984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp1_parse0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.281437</td>\n",
       "      <td>0.281437</td>\n",
       "      <td>0.032934</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.605098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp2_parse0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.068862</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.035928</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.513208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp3_parse0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.035928</td>\n",
       "      <td>0.032934</td>\n",
       "      <td>0.014970</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.517149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp4_parse0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.886228</td>\n",
       "      <td>0.449102</td>\n",
       "      <td>0.008982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>289</td>\n",
       "      <td>0.993127</td>\n",
       "      <td>0.830904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp5_parse0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.008982</td>\n",
       "      <td>0.008982</td>\n",
       "      <td>0.008982</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.517013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp5_parse1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.008982</td>\n",
       "      <td>0.008982</td>\n",
       "      <td>0.008982</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.515533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp6_parse0</th>\n",
       "      <td>7</td>\n",
       "      <td>0.029940</td>\n",
       "      <td>0.029940</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.537478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp6_parse1</th>\n",
       "      <td>8</td>\n",
       "      <td>0.029940</td>\n",
       "      <td>0.029940</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.537213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp7_parse0</th>\n",
       "      <td>9</td>\n",
       "      <td>0.029940</td>\n",
       "      <td>0.023952</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.528035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp8_parse0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.005988</td>\n",
       "      <td>0.005988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.519782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp8_parse1</th>\n",
       "      <td>11</td>\n",
       "      <td>0.005988</td>\n",
       "      <td>0.005988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.518567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp9_parse0</th>\n",
       "      <td>12</td>\n",
       "      <td>0.038922</td>\n",
       "      <td>0.035928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.532898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              j  Coverage  Overlaps  Conflicts  TP  FP  FN   TN  \\\n",
       "exp0_parse0   0  0.398204  0.395210   0.029940   0   0   3  127   \n",
       "exp1_parse0   1  0.281437  0.281437   0.032934   0   0   3   90   \n",
       "exp2_parse0   2  0.068862  0.053892   0.035928  10  13   0    0   \n",
       "exp3_parse0   3  0.035928  0.032934   0.014970   6   6   0    0   \n",
       "exp4_parse0   4  0.886228  0.449102   0.008982   0   0   2  289   \n",
       "exp5_parse0   5  0.008982  0.008982   0.008982   1   2   0    0   \n",
       "exp5_parse1   6  0.008982  0.008982   0.008982   1   2   0    0   \n",
       "exp6_parse0   7  0.029940  0.029940   0.002994   0   0   0   10   \n",
       "exp6_parse1   8  0.029940  0.029940   0.002994   0   0   0   10   \n",
       "exp7_parse0   9  0.029940  0.023952   0.002994   0   0   1    9   \n",
       "exp8_parse0  10  0.005988  0.005988   0.000000   0   0   0    2   \n",
       "exp8_parse1  11  0.005988  0.005988   0.000000   0   0   0    2   \n",
       "exp9_parse0  12  0.038922  0.035928   0.000000   0   0   0   13   \n",
       "\n",
       "             Empirical Acc.  Learned Acc.  \n",
       "exp0_parse0        0.976923      0.653984  \n",
       "exp1_parse0        0.967742      0.605098  \n",
       "exp2_parse0        0.434783      0.513208  \n",
       "exp3_parse0        0.500000      0.517149  \n",
       "exp4_parse0        0.993127      0.830904  \n",
       "exp5_parse0        0.333333      0.517013  \n",
       "exp5_parse1        0.333333      0.515533  \n",
       "exp6_parse0        1.000000      0.537478  \n",
       "exp6_parse1        1.000000      0.537213  \n",
       "exp7_parse0        0.900000      0.528035  \n",
       "exp8_parse0        1.000000      0.519782  \n",
       "exp8_parse1        1.000000      0.518567  \n",
       "exp9_parse0        1.000000      0.532898  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_dev.lf_stats(session, L_gold_dev, gen_model.weights.lf_accuracy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import SparseLogisticRegression\n",
    "disc_model = SparseLogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized RandomSearch search of size 20. Search space size = 125.\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning.utils import MentionScorer\n",
    "from snorkel.learning import RandomSearch, ListParameter, RangeParameter\n",
    "\n",
    "# Searching over learning rate\n",
    "rate_param = RangeParameter('lr', 1e-6, 1e-2, step=1, log_base=10)\n",
    "l1_param  = RangeParameter('l1_penalty', 1e-6, 1e-2, step=1, log_base=10)\n",
    "l2_param  = RangeParameter('l2_penalty', 1e-6, 1e-2, step=1, log_base=10)\n",
    "\n",
    "searcher = RandomSearch(session, disc_model, F_unlabeled, train_marginals, [rate_param, l1_param, l2_param], n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "[1] Testing lr = 1.00e-02, l1_penalty = 1.00e-03, l2_penalty = 1.00e-04\n",
      "============================================================\n",
      "[SparseLR] lr=0.01 l1=0.001 l2=0.0001\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=152  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.20s)\tAvg. loss=0.677195\tNNZ=3025\n",
      "[SparseLR] Epoch 25 (0.31s)\tAvg. loss=0.475742\tNNZ=3025\n",
      "[SparseLR] Epoch 49 (0.43s)\tAvg. loss=0.457101\tNNZ=3025\n",
      "[SparseLR] Training done (0.43s)\n",
      "[SparseLR] Model saved. To load, use name\n",
      "\t\tSparseLR_0\n",
      "============================================================\n",
      "[2] Testing lr = 1.00e-04, l1_penalty = 1.00e-06, l2_penalty = 1.00e-03\n",
      "============================================================\n",
      "[SparseLR] lr=0.0001 l1=1e-06 l2=0.001\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=152  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.20s)\tAvg. loss=0.684048\tNNZ=3025\n",
      "[SparseLR] Epoch 25 (0.32s)\tAvg. loss=0.661457\tNNZ=3025\n",
      "[SparseLR] Epoch 49 (0.43s)\tAvg. loss=0.643269\tNNZ=3025\n",
      "[SparseLR] Training done (0.43s)\n",
      "============================================================\n",
      "[3] Testing lr = 1.00e-03, l1_penalty = 1.00e-05, l2_penalty = 1.00e-05\n",
      "============================================================\n",
      "[SparseLR] lr=0.001 l1=1e-05 l2=1e-05\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=152  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.20s)\tAvg. loss=0.684203\tNNZ=3025\n",
      "[SparseLR] Epoch 25 (0.32s)\tAvg. loss=0.566036\tNNZ=3025\n",
      "[SparseLR] Epoch 49 (0.44s)\tAvg. loss=0.536752\tNNZ=3025\n",
      "[SparseLR] Training done (0.44s)\n",
      "============================================================\n",
      "[4] Testing lr = 1.00e-03, l1_penalty = 1.00e-06, l2_penalty = 1.00e-03\n",
      "============================================================\n",
      "[SparseLR] lr=0.001 l1=1e-06 l2=0.001\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=152  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.19s)\tAvg. loss=0.690382\tNNZ=3025\n",
      "[SparseLR] Epoch 25 (0.29s)\tAvg. loss=0.567993\tNNZ=3025\n",
      "[SparseLR] Epoch 49 (0.40s)\tAvg. loss=0.538987\tNNZ=3025\n",
      "[SparseLR] Training done (0.40s)\n",
      "============================================================\n",
      "[5] Testing lr = 1.00e-02, l1_penalty = 1.00e-04, l2_penalty = 1.00e-05\n",
      "============================================================\n",
      "[SparseLR] lr=0.01 l1=0.0001 l2=1e-05\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=152  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.20s)\tAvg. loss=0.679632\tNNZ=3025\n",
      "[SparseLR] Epoch 25 (0.31s)\tAvg. loss=0.485287\tNNZ=3025\n",
      "[SparseLR] Epoch 49 (0.42s)\tAvg. loss=0.467555\tNNZ=3025\n",
      "[SparseLR] Training done (0.42s)\n",
      "[SparseLR] Model saved. To load, use name\n",
      "\t\tSparseLR_4\n",
      "============================================================\n",
      "[6] Testing lr = 1.00e-06, l1_penalty = 1.00e-03, l2_penalty = 1.00e-05\n",
      "============================================================\n",
      "[SparseLR] lr=1e-06 l1=0.001 l2=1e-05\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=152  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.21s)\tAvg. loss=0.690960\tNNZ=3025\n",
      "[SparseLR] Epoch 25 (0.35s)\tAvg. loss=0.690478\tNNZ=3025\n",
      "[SparseLR] Epoch 49 (0.46s)\tAvg. loss=0.690018\tNNZ=3025\n",
      "[SparseLR] Training done (0.46s)\n",
      "============================================================\n",
      "[7] Testing lr = 1.00e-06, l1_penalty = 1.00e-03, l2_penalty = 1.00e-02\n",
      "============================================================\n",
      "[SparseLR] lr=1e-06 l1=0.001 l2=0.01\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=152  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.23s)\tAvg. loss=0.688662\tNNZ=3025\n",
      "[SparseLR] Epoch 25 (0.33s)\tAvg. loss=0.688256\tNNZ=3025\n",
      "[SparseLR] Epoch 49 (0.43s)\tAvg. loss=0.687869\tNNZ=3025\n",
      "[SparseLR] Training done (0.43s)\n",
      "============================================================\n",
      "[8] Testing lr = 1.00e-02, l1_penalty = 1.00e-05, l2_penalty = 1.00e-02\n",
      "============================================================\n",
      "[SparseLR] lr=0.01 l1=1e-05 l2=0.01\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=152  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.21s)\tAvg. loss=0.684450\tNNZ=3025\n",
      "[SparseLR] Epoch 25 (0.31s)\tAvg. loss=0.472408\tNNZ=3025\n",
      "[SparseLR] Epoch 49 (0.42s)\tAvg. loss=0.454563\tNNZ=3025\n",
      "[SparseLR] Training done (0.42s)\n",
      "============================================================\n",
      "[9] Testing lr = 1.00e-04, l1_penalty = 1.00e-02, l2_penalty = 1.00e-06\n",
      "============================================================\n",
      "[SparseLR] lr=0.0001 l1=0.01 l2=1e-06\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=152  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.21s)\tAvg. loss=0.683574\tNNZ=3025\n",
      "[SparseLR] Epoch 25 (0.32s)\tAvg. loss=0.660444\tNNZ=3025\n",
      "[SparseLR] Epoch 49 (0.42s)\tAvg. loss=0.642766\tNNZ=3025\n",
      "[SparseLR] Training done (0.42s)\n",
      "============================================================\n",
      "[10] Testing lr = 1.00e-06, l1_penalty = 1.00e-05, l2_penalty = 1.00e-03\n",
      "============================================================\n",
      "[SparseLR] lr=1e-06 l1=1e-05 l2=0.001\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=152  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.22s)\tAvg. loss=0.690934\tNNZ=3025\n",
      "[SparseLR] Epoch 25 (0.33s)\tAvg. loss=0.694690\tNNZ=3025\n",
      "[SparseLR] Epoch 49 (0.43s)\tAvg. loss=0.694203\tNNZ=3025\n",
      "[SparseLR] Training done (0.43s)\n",
      "============================================================\n",
      "[11] Testing lr = 1.00e-04, l1_penalty = 1.00e-02, l2_penalty = 1.00e-04\n",
      "============================================================\n",
      "[SparseLR] lr=0.0001 l1=0.01 l2=0.0001\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=152  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.23s)\tAvg. loss=0.684834\tNNZ=3025\n",
      "[SparseLR] Epoch 25 (0.33s)\tAvg. loss=0.659411\tNNZ=3025\n",
      "[SparseLR] Epoch 49 (0.44s)\tAvg. loss=0.640992\tNNZ=3025\n",
      "[SparseLR] Training done (0.44s)\n",
      "============================================================\n",
      "[12] Testing lr = 1.00e-03, l1_penalty = 1.00e-06, l2_penalty = 1.00e-03\n",
      "============================================================\n",
      "[SparseLR] lr=0.001 l1=1e-06 l2=0.001\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=152  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.24s)\tAvg. loss=0.691227\tNNZ=3025\n",
      "[SparseLR] Epoch 25 (0.34s)\tAvg. loss=0.579726\tNNZ=3025\n",
      "[SparseLR] Epoch 49 (0.45s)\tAvg. loss=0.549964\tNNZ=3025\n",
      "[SparseLR] Training done (0.45s)\n",
      "============================================================\n",
      "[13] Testing lr = 1.00e-04, l1_penalty = 1.00e-04, l2_penalty = 1.00e-05\n",
      "============================================================\n",
      "[SparseLR] lr=0.0001 l1=0.0001 l2=1e-05\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=152  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.24s)\tAvg. loss=0.685161\tNNZ=3025\n",
      "[SparseLR] Epoch 25 (0.35s)\tAvg. loss=0.662619\tNNZ=3025\n",
      "[SparseLR] Epoch 49 (0.45s)\tAvg. loss=0.645139\tNNZ=3025\n",
      "[SparseLR] Training done (0.45s)\n",
      "============================================================\n",
      "[14] Testing lr = 1.00e-03, l1_penalty = 1.00e-05, l2_penalty = 1.00e-04\n",
      "============================================================\n",
      "[SparseLR] lr=0.001 l1=1e-05 l2=0.0001\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=152  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.43s)\tAvg. loss=0.693017\tNNZ=3025\n",
      "[SparseLR] Epoch 25 (0.54s)\tAvg. loss=0.575555\tNNZ=3025\n",
      "[SparseLR] Epoch 49 (0.64s)\tAvg. loss=0.544846\tNNZ=3025\n",
      "[SparseLR] Training done (0.64s)\n",
      "============================================================\n",
      "[15] Testing lr = 1.00e-04, l1_penalty = 1.00e-02, l2_penalty = 1.00e-05\n",
      "============================================================\n",
      "[SparseLR] lr=0.0001 l1=0.01 l2=1e-05\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=152  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.25s)\tAvg. loss=0.692818\tNNZ=3025\n",
      "[SparseLR] Epoch 25 (0.36s)\tAvg. loss=0.664105\tNNZ=3025\n",
      "[SparseLR] Epoch 49 (0.46s)\tAvg. loss=0.643422\tNNZ=3025\n",
      "[SparseLR] Training done (0.46s)\n",
      "============================================================\n",
      "[16] Testing lr = 1.00e-05, l1_penalty = 1.00e-06, l2_penalty = 1.00e-04\n",
      "============================================================\n",
      "[SparseLR] lr=1e-05 l1=1e-06 l2=0.0001\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=152  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.28s)\tAvg. loss=0.691814\tNNZ=3025\n",
      "[SparseLR] Epoch 25 (0.38s)\tAvg. loss=0.687456\tNNZ=3025\n",
      "[SparseLR] Epoch 49 (0.48s)\tAvg. loss=0.684445\tNNZ=3025\n",
      "[SparseLR] Training done (0.48s)\n",
      "============================================================\n",
      "[17] Testing lr = 1.00e-06, l1_penalty = 1.00e-02, l2_penalty = 1.00e-03\n",
      "============================================================\n",
      "[SparseLR] lr=1e-06 l1=0.01 l2=0.001\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=152  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.33s)\tAvg. loss=0.693458\tNNZ=3025\n",
      "[SparseLR] Epoch 25 (0.45s)\tAvg. loss=0.695437\tNNZ=3025\n",
      "[SparseLR] Epoch 49 (0.56s)\tAvg. loss=0.694948\tNNZ=3025\n",
      "[SparseLR] Training done (0.56s)\n",
      "============================================================\n",
      "[18] Testing lr = 1.00e-02, l1_penalty = 1.00e-05, l2_penalty = 1.00e-06\n",
      "============================================================\n",
      "[SparseLR] lr=0.01 l1=1e-05 l2=1e-06\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=152  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.27s)\tAvg. loss=0.689251\tNNZ=3025\n",
      "[SparseLR] Epoch 25 (0.38s)\tAvg. loss=0.480536\tNNZ=3025\n",
      "[SparseLR] Epoch 49 (0.49s)\tAvg. loss=0.463234\tNNZ=3025\n",
      "[SparseLR] Training done (0.49s)\n",
      "[SparseLR] Model saved. To load, use name\n",
      "\t\tSparseLR_17\n",
      "============================================================\n",
      "[19] Testing lr = 1.00e-05, l1_penalty = 1.00e-02, l2_penalty = 1.00e-06\n",
      "============================================================\n",
      "[SparseLR] lr=1e-05 l1=0.01 l2=1e-06\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=152  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.27s)\tAvg. loss=0.691920\tNNZ=3025\n",
      "[SparseLR] Epoch 25 (0.39s)\tAvg. loss=0.688732\tNNZ=3025\n",
      "[SparseLR] Epoch 49 (0.50s)\tAvg. loss=0.685752\tNNZ=3025\n",
      "[SparseLR] Training done (0.50s)\n",
      "============================================================\n",
      "[20] Testing lr = 1.00e-02, l1_penalty = 1.00e-05, l2_penalty = 1.00e-04\n",
      "============================================================\n",
      "[SparseLR] lr=0.01 l1=1e-05 l2=0.0001\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=152  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (0.29s)\tAvg. loss=0.680724\tNNZ=3025\n",
      "[SparseLR] Epoch 25 (0.41s)\tAvg. loss=0.471417\tNNZ=3025\n",
      "[SparseLR] Epoch 49 (0.51s)\tAvg. loss=0.453463\tNNZ=3025\n",
      "[SparseLR] Training done (0.51s)\n",
      "[SparseLR] Loaded model <SparseLR_17>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>l1_penalty</th>\n",
       "      <th>l2_penalty</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>Rec.</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.032727</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.062718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.030651</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.058608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.028409</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.053191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.028302</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.050847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.029197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.021978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lr  l1_penalty  l2_penalty     Prec.      Rec.        F1\n",
       "17  0.010000    0.000010    0.000001  0.666667  0.166667  0.266667\n",
       "4   0.010000    0.000100    0.000010  0.500000  0.166667  0.250000\n",
       "7   0.010000    0.000010    0.010000  0.500000  0.166667  0.250000\n",
       "19  0.010000    0.000010    0.000100  0.333333  0.166667  0.222222\n",
       "0   0.010000    0.001000    0.000100  0.222222  0.166667  0.190476\n",
       "9   0.000001    0.000010    0.001000  0.032727  0.750000  0.062718\n",
       "16  0.000001    0.010000    0.001000  0.030651  0.666667  0.058608\n",
       "5   0.000001    0.001000    0.000010  0.028409  0.416667  0.053191\n",
       "18  0.000010    0.010000    0.000001  0.028302  0.250000  0.050847\n",
       "6   0.000001    0.001000    0.010000  0.016000  0.166667  0.029197\n",
       "15  0.000010    0.000001    0.000100  0.012658  0.083333  0.021978\n",
       "3   0.001000    0.000001    0.001000  0.000000  0.000000  0.000000\n",
       "8   0.000100    0.010000    0.000001  0.000000  0.000000  0.000000\n",
       "1   0.000100    0.000001    0.001000  0.000000  0.000000  0.000000\n",
       "11  0.001000    0.000001    0.001000  0.000000  0.000000  0.000000\n",
       "12  0.000100    0.000100    0.000010  0.000000  0.000000  0.000000\n",
       "13  0.001000    0.000010    0.000100  0.000000  0.000000  0.000000\n",
       "14  0.000100    0.010000    0.000010  0.000000  0.000000  0.000000\n",
       "2   0.001000    0.000010    0.000010  0.000000  0.000000  0.000000\n",
       "10  0.000100    0.010000    0.000100  0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1701)\n",
    "searcher.fit(F_dev, L_gold_dev, n_epochs=50, rebalance=True, print_freq=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# disc_model.train(F_unlabeled, train_marginals, n_epochs=20, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.167\n",
      "Neg. class accuracy: 0.997\n",
      "Precision            0.667\n",
      "Recall               0.167\n",
      "F1                   0.267\n",
      "----------------------------------------\n",
      "TP: 2 | FP: 1 | TN: 321 | FN: 10\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TP, FP, TN, FN = disc_model.score(session, F_dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "snorkel.models.candidate.Spouse"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(list(TP)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-butt": {},
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
