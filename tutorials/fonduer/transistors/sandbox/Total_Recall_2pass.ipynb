{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.remove('snorkel.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os, sys\n",
    "sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from snorkel.parser import CorpusParser, HTMLParser, OmniParser\n",
    "from snorkel.utils import get_ORM_instance\n",
    "from snorkel.queries import split_corpus\n",
    "\n",
    "html_path = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware100_html/'\n",
    "pdf_path  = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware100_pdf/'\n",
    "doc_parser = HTMLParser(path=html_path)\n",
    "context_parser = OmniParser(pdf_path=pdf_path, session=session)\n",
    "cp = CorpusParser(doc_parser, context_parser, max_docs=100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time corpus = cp.parse_corpus(name='Hardware', session=session)\n",
    "\n",
    "session.add(corpus)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "import os\n",
    "os.system('cp snorkel.db snorkel.db\\ corpus');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If necessary:\n",
    "import os\n",
    "os.remove('snorkel.db');\n",
    "os.system('cp snorkel.db\\ corpus snorkel.db');\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "Part = candidate_subclass('Part', ['part'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Matchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.matchers import RegexMatchSpan, Union\n",
    "\n",
    "eeca_rgx = ur'([b]{1}[abcdefklnpqruyz]{1}[\\swxyz]?[0-9]{3,5}[\\s]?[A-Z]{0,2}[\\/]?[A-Z]{0,2}[0-9]?[A-Z]?([(\\-|\\u2010|\\u2011|\\u2012|\\u2013|\\u2014|\\u2212)][A-Z0-9]{1,7})?([(\\-|\\u2010|\\u2011|\\u2012|\\u2013|\\u2014|\\u2212)][A-Z0-9]{1,2})?)'\n",
    "eeca_matcher = RegexMatchSpan(rgx=eeca_rgx, longest_match_only=True)\n",
    "jedec_rgx = '([123]N\\d{3,4}[A-Z]{0,5}[0-9]?[A-Z]?)'\n",
    "jedec_matcher = RegexMatchSpan(rgx=jedec_rgx, longest_match_only=True)\n",
    "jis_rgx = '(2S[abcdefghjkmqrstvz]{1}[\\d]{2,4})'\n",
    "jis_matcher = RegexMatchSpan(rgx=jis_rgx, longest_match_only=True)\n",
    "others_rgx = '((NSVBC|SMBT|MJ|MJE|MPS|MRF|RCA|TIP|ZTX|ZT|TIS|TIPL|DTC|MMBT|PZT){1}[\\d]{2,4}[A-Z]{0,3}([-][A-Z0-9]{0,6})?([-][A-Z0-9]{0,1})?)'\n",
    "others_matcher = RegexMatchSpan(rgx=others_rgx, longest_match_only=True)\n",
    "# parts_rgx = '|'.join([eeca_rgx, jedec_rgx, jis_rgx, others_rgx])\n",
    "parts_matcher = Union(eeca_matcher, jedec_matcher, jis_matcher, others_matcher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define ContextSpaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from hardware_utils import OmniNgramsPart, get_gold_dict, expand_part_range\n",
    "from snorkel.utils import ProgressBar\n",
    "from snorkel.lf_helpers import *\n",
    "from snorkel.utils import get_ORM_instance\n",
    "from snorkel.models import Corpus\n",
    "from snorkel.candidates import OmniNgrams\n",
    "\n",
    "# # 1 Pass to find all suffixes using a suffix matcher\n",
    "corpus = get_ORM_instance(Corpus, session, 'Hardware')\n",
    "\n",
    "eeca_suffix = '^(A|B|C|-16|-25|-40|16|25|40)$'\n",
    "suffix_matcher = RegexMatchSpan(rgx=eeca_suffix, ignore_case=False)\n",
    "\n",
    "suffix_ngrams = OmniNgrams(n_max=1)\n",
    "\n",
    "part_ngrams = OmniNgramsPart(n_max=5) # need to expand it automatically\n",
    "\n",
    "def extract_dicts(contexts, session):\n",
    "    suffixes_by_doc = defaultdict(set)\n",
    "    parts_by_doc = defaultdict(set)\n",
    "    final_dict = defaultdict(set)\n",
    "    mapping = [ (u'\\u2010', '-'),\n",
    "                (u'\\u2011', '-'),\n",
    "                (u'\\u2012', '-'),\n",
    "                (u'\\u2013', '-'),\n",
    "                (u'\\u2014', '-'),\n",
    "                (u'\\u2212', '-'),\n",
    "              ]\n",
    "    pb = ProgressBar(len(contexts))\n",
    "    for i, context in enumerate(contexts):\n",
    "        pb.bar(i)\n",
    "        # Extract Suffixes\n",
    "        for ts in suffix_matcher.apply(suffix_ngrams.apply(context)):\n",
    "            row_ngrams = set(get_row_ngrams(ts, infer=True))\n",
    "            if ('classification' in row_ngrams or \n",
    "                'group' in row_ngrams or\n",
    "                'rank' in row_ngrams or\n",
    "                'grp.' in row_ngrams):\n",
    "                suffixes_by_doc[ts.parent.document.name.upper()].add(ts.get_span())\n",
    "        \n",
    "        #extract parts\n",
    "        for ts in parts_matcher.apply(part_ngrams.apply(context)):\n",
    "            text = ts.get_span()\n",
    "            for k, v in mapping:\n",
    "                text = text.replace(k, v)\n",
    "            if text.endswith('/') or text.endswith('-'):\n",
    "                continue\n",
    "                \n",
    "            if \"PNP\" in text or \"NPN\" in text:\n",
    "                continue\n",
    "                \n",
    "            parts_by_doc[ts.parent.document.name.upper()].add(text)\n",
    "    \n",
    "    pb.close()\n",
    "    \n",
    "    # Process suffixes and parts\n",
    "    for doc in parts_by_doc.keys():\n",
    "        for part in parts_by_doc[doc]:\n",
    "            final_dict[doc].add(part)\n",
    "            for suffix in suffixes_by_doc[doc]:\n",
    "                if (suffix == \"A\" or suffix == \"B\" or suffix == \"C\"):\n",
    "                    if not any(x in part[2:] for x in ['A', 'B', 'C']):\n",
    "                        final_dict[doc].add(part + suffix)\n",
    "                else: # if it's 16/25/40\n",
    "                    if not suffix.startswith('-') and not any(x in part for x in ['16', '25', '40']):\n",
    "                        final_dict[doc].add(part + '-' + suffix)\n",
    "                    elif suffix.startswith('-') and not any(x in part for x in ['16', '25', '40']):\n",
    "                        final_dict[doc].add(part + suffix)\n",
    "\n",
    "    # TODO: Just return final_set. Temporarily returning the other two for\n",
    "    # easier debugging.\n",
    "    return final_dict, suffixes_by_doc, parts_by_doc\n",
    "            \n",
    "parts, s, p = extract_dicts(corpus.documents, session)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = '1stpass.pkl'\n",
    "with open(filename, 'w') as f:\n",
    "    pickle.dump([parts, s, p], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = '1stpass.pkl'\n",
    "with open(filename, 'r') as f:\n",
    "    [parts, s, p] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'BC546',\n",
      " u'BC546A',\n",
      " u'BC546ABU',\n",
      " u'BC546ATA',\n",
      " u'BC546B',\n",
      " u'BC546BTA',\n",
      " u'BC546BTF',\n",
      " u'BC546C',\n",
      " u'BC546CTA',\n",
      " u'BC547',\n",
      " u'BC547A',\n",
      " u'BC547ATA',\n",
      " u'BC547B',\n",
      " u'BC547BBU',\n",
      " u'BC547BTA',\n",
      " u'BC547BTF',\n",
      " u'BC547C',\n",
      " u'BC547CBU',\n",
      " u'BC547CTA',\n",
      " u'BC547CTFR',\n",
      " u'BC548',\n",
      " u'BC548A',\n",
      " u'BC548B',\n",
      " u'BC548BTA',\n",
      " u'BC548BU',\n",
      " u'BC548C',\n",
      " u'BC548CTA',\n",
      " u'BC549',\n",
      " u'BC549A',\n",
      " u'BC549B',\n",
      " u'BC549BTA',\n",
      " u'BC549BTF',\n",
      " u'BC549C',\n",
      " u'BC549CTA',\n",
      " u'BC550',\n",
      " u'BC550A',\n",
      " u'BC550B',\n",
      " u'BC550C',\n",
      " u'BC550CBU',\n",
      " u'BC550CTA',\n",
      " u'BC556',\n",
      " u'BC556A',\n",
      " u'BC556B',\n",
      " u'BC556C',\n",
      " u'BC557',\n",
      " u'BC557A',\n",
      " u'BC557B',\n",
      " u'BC557C',\n",
      " u'BC558',\n",
      " u'BC558A',\n",
      " u'BC558B',\n",
      " u'BC558C',\n",
      " u'BC559',\n",
      " u'BC559A',\n",
      " u'BC559B',\n",
      " u'BC559C',\n",
      " u'BC560',\n",
      " u'BC560A',\n",
      " u'BC560B',\n",
      " u'BC560C']\n",
      "[u'16', u'BC337\\u201316', u'BC337\\u201316/BC338\\u201316', u'BC338', u'BC338\\u201316']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from hardware_utils import OmniNgramsPart, get_gold_dict, expand_part_range  \n",
    "pprint(sorted([part for part in parts['BC546']]))\n",
    "\n",
    "print(sorted([x for x in expand_part_range(u\"BC337–16/BC338–16\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Enhance CandidateExtractor to add these suffixes to the parts found in the parts_matcher\n",
    "from hardware_utils import get_gold_dict\n",
    "from collections import defaultdict\n",
    "\n",
    "# Make parts list\n",
    "gold_file = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "\n",
    "# # Gold parts looks like this:\n",
    "#     # set([('112823', 'BC546'),\n",
    "#     #      ('112823', 'BC546B'),\n",
    "#     #      ('112823', 'BC546BG'),            if ts.parent.document.name.upper() == \"MOTOS03189-1\":\n",
    "#     #      ('112823', 'BC546BRL1'),\n",
    "#     #      ('112823', 'BC546BRL1G'),\n",
    "#     #      ('112823', 'BC546BZL1G'),\n",
    "#     #      ('112823', 'BC547'),\n",
    "#     #      ('112823', 'BC547A'),\n",
    "#     #      ('112823', 'BC547ARL'),\n",
    "#     #      ('112823', 'BC547ARLG'),\n",
    "#     #      ('112823', 'BC547AZL1G'),\n",
    "#     #      ('112823', 'BC547B'),\n",
    "#     #      ('112823', 'BC547BG'),\n",
    "gold_parts = get_gold_dict(gold_file, doc_on=True, part_on=True, val_on=False)\n",
    "\n",
    "gold = set()\n",
    "gold_parts_by_doc = defaultdict(set)\n",
    "for part in gold_parts:\n",
    "    gold_parts_by_doc[part[0]].add(part[1])\n",
    "    gold.add((part[0], part[1]))\n",
    "print len(gold)\n",
    "\n",
    "homemade = set()\n",
    "for doc, parts in parts.iteritems():\n",
    "    for part in parts:\n",
    "        homemade.add((doc,part))\n",
    "print len(homemade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tp = gold.intersection(homemade)\n",
    "fp = homemade - gold\n",
    "fn = gold - homemade\n",
    "print \"TP: \", len(tp)\n",
    "print \"FP: \", len(fp)\n",
    "print \"FN: \", len(fn)\n",
    "print \"TOTAL: \", len(tp) + len(fp) + len(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hardware_utils import OmniNgramsPart\n",
    "\n",
    "part_ngrams = OmniNgramsPart(parts_by_doc=parts, n_max=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run CandidateExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Candidates from Corpus (Hardware)\n",
      "[========================================] 100%\n",
      "CPU times: user 1min 8s, sys: 584 ms, total: 1min 8s\n",
      "Wall time: 1min 8s\n",
      "Candidate Set (Hardware Candidates) contains 23841 Candidates\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Corpus\n",
    "from snorkel.candidates import CandidateExtractor\n",
    "from snorkel.utils import get_ORM_instance\n",
    "\n",
    "\n",
    "ce = CandidateExtractor(Part, \n",
    "                        [part_ngrams], \n",
    "                        [parts_matcher])\n",
    "\n",
    "for corpus_name in ['Hardware']:\n",
    "    corpus = get_ORM_instance(Corpus, session, corpus_name)\n",
    "    print \"Extracting Candidates from %s\" % corpus\n",
    "    %time candidates = ce.extract(\\\n",
    "        corpus.documents, corpus_name + ' Candidates', session)\n",
    "    session.add(candidates)\n",
    "    print \"%s contains %d Candidates\" % (candidates, len(candidates))\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess Recall\n",
    "\n",
    "Using the dictionary approach we have\n",
    "\n",
    "- **24820** candidates for part numbers\n",
    "- 811 entity-level candidates and **100% recall**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing candidates...\n",
      "[========================================] 100%\n",
      "========================================\n",
      "Scoring on Entity-Level Total Recall\n",
      "========================================\n",
      "Entity-level Candidates extracted: 1732 \n",
      "Entity-level Gold: 809\n",
      "Intersection Candidates: 806\n",
      "----------------------------------------\n",
      "Overlap with Gold:  0.9963\n",
      "========================================\n",
      "\n",
      "TP:  806\n",
      "FP:  926\n",
      "FN:  3\n",
      "TOTAL:  1735\n"
     ]
    }
   ],
   "source": [
    "from hardware_utils import entity_level_total_recall, most_common_document, get_gold_dict\n",
    "from snorkel.utils import get_ORM_instance\n",
    "from snorkel.models import Candidate, Corpus\n",
    "\n",
    "all_candidates = session.query(Candidate).all()\n",
    "gold_file = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "\n",
    "corpus = get_ORM_instance(Corpus, session, 'Hardware')\n",
    "(tp, fp, fn) = entity_level_total_recall(\n",
    "    all_candidates, gold_file, None, corpus=corpus, relation=False)\n",
    "print \"TP: \", len(tp)\n",
    "print \"FP: \", len(fp)\n",
    "print \"FN: \", len(fn)\n",
    "print \"TOTAL: \", len(tp) + len(fp) + len(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'112823', u'BC546/D'),\n",
      " (u'112823', u'BC548A'),\n",
      " (u'2N3906-D', u'1N916'),\n",
      " (u'2N3906-D', u'1N916C'),\n",
      " (u'2N3906-D', u'1N916CS'),\n",
      " (u'2N3906-D', u'2N390D'),\n",
      " (u'2N4123-D', u'2N412D'),\n",
      " (u'2N4124', u'1N916'),\n",
      " (u'2N6426-D', u'2N6426IS'),\n",
      " (u'2N6426-D', u'2N6426ISA'),\n",
      " (u'2N6426-D', u'2N642D'),\n",
      " (u'AUKCS04635-1', u'2N3904'),\n",
      " (u'BC182-D', u'BC182/D'),\n",
      " (u'BC337', u'BC327'),\n",
      " (u'BC337', u'BC327-16'),\n",
      " (u'BC337', u'BC327-25'),\n",
      " (u'BC337', u'BC327-40'),\n",
      " (u'BC337', u'BC328'),\n",
      " (u'BC337', u'BC328-16'),\n",
      " (u'BC337', u'BC328-25'),\n",
      " (u'BC337', u'BC328-40'),\n",
      " (u'BC337', u'BC33716'),\n",
      " (u'BC337', u'BC33725'),\n",
      " (u'BC337', u'BC33740'),\n",
      " (u'BC337', u'BC33740BU'),\n",
      " (u'BC337', u'BC338-16'),\n",
      " (u'BC337', u'BC338-40'),\n",
      " (u'BC337', u'BC33825'),\n",
      " (u'BC337-D', u'BC337-25BC337'),\n",
      " (u'BC337-D', u'BC337-XX'),\n",
      " (u'BC337-D', u'BC337/D'),\n",
      " (u'BC546', u'BC548A'),\n",
      " (u'BC546', u'BC549A'),\n",
      " (u'BC546', u'BC550A'),\n",
      " (u'BC546', u'BC550B'),\n",
      " (u'BC546', u'BC556'),\n",
      " (u'BC546', u'BC556A'),\n",
      " (u'BC546', u'BC556B'),\n",
      " (u'BC546', u'BC556C'),\n",
      " (u'BC546', u'BC557'),\n",
      " (u'BC546', u'BC557A'),\n",
      " (u'BC546', u'BC557B'),\n",
      " (u'BC546', u'BC557C'),\n",
      " (u'BC546', u'BC558'),\n",
      " (u'BC546', u'BC558A'),\n",
      " (u'BC546', u'BC558B'),\n",
      " (u'BC546', u'BC558C'),\n",
      " (u'BC546', u'BC559'),\n",
      " (u'BC546', u'BC559A'),\n",
      " (u'BC546', u'BC559B'),\n",
      " (u'BC546', u'BC559C'),\n",
      " (u'BC546', u'BC560'),\n",
      " (u'BC546', u'BC560A'),\n",
      " (u'BC546', u'BC560B'),\n",
      " (u'BC546', u'BC560C'),\n",
      " (u'BC546-BC548C(TO-92)', u'BC546-BC548C'),\n",
      " (u'BC546-BC548C(TO-92)', u'BC546THRU'),\n",
      " (u'BC546-D', u'BC546/D'),\n",
      " (u'BC546-D', u'BC548A'),\n",
      " (u'BC546A_SERIES_B14-521026', u'BC546AA1G'),\n",
      " (u'BC546A_SERIES_B14-521026', u'BC547BA1'),\n",
      " (u'BC546A_SERIES_B14-521026', u'BC550BA1'),\n",
      " (u'BC546A_SERIES_B14-521026', u'BC550I'),\n",
      " (u'BC546A_SERIES_B14-521026', u'BC550IA'),\n",
      " (u'BC546A_SERIES_B14-521026', u'BC550IC'),\n",
      " (u'BC546A_SERIES_B14-521026', u'BC550IE'),\n",
      " (u'BC546A_SERIES_B14-521026', u'BC550IEA'),\n",
      " (u'BC546_DIOTEC', u'BC546C'),\n",
      " (u'BC546_DIOTEC', u'BC547F'),\n",
      " (u'BC546_DIOTEC', u'BC547FA'),\n",
      " (u'BC546_DIOTEC', u'BC547FB'),\n",
      " (u'BC546_DIOTEC', u'BC547FC'),\n",
      " (u'BC546_DIOTEC', u'BC549A'),\n",
      " (u'BC546_DIOTEC', u'BC549F'),\n",
      " (u'BC546_DIOTEC', u'BC549FA'),\n",
      " (u'BC546_DIOTEC', u'BC549FB'),\n",
      " (u'BC546_DIOTEC', u'BC549FC'),\n",
      " (u'BC546_DIOTEC', u'BC556'),\n",
      " (u'BC546_DIOTEC', u'BC556A'),\n",
      " (u'BC546_DIOTEC', u'BC556B'),\n",
      " (u'BC546_DIOTEC', u'BC556C'),\n",
      " (u'BC546_DIOTEC', u'BC557'),\n",
      " (u'BC546_DIOTEC', u'BC557A'),\n",
      " (u'BC546_DIOTEC', u'BC557B'),\n",
      " (u'BC546_DIOTEC', u'BC557C'),\n",
      " (u'BC546_DIOTEC', u'BC558'),\n",
      " (u'BC546_DIOTEC', u'BC558A'),\n",
      " (u'BC546_DIOTEC', u'BC558B'),\n",
      " (u'BC546_DIOTEC', u'BC558C'),\n",
      " (u'BC546_DIOTEC', u'BC559'),\n",
      " (u'BC546_DIOTEC', u'BC559A'),\n",
      " (u'BC546_DIOTEC', u'BC559B'),\n",
      " (u'BC546_DIOTEC', u'BC559C'),\n",
      " (u'BC547', u'BC548A'),\n",
      " (u'BC547', u'BC548BU'),\n",
      " (u'BC547', u'BC549A'),\n",
      " (u'BC547', u'BC550A'),\n",
      " (u'BC547', u'BC550B'),\n",
      " (u'BC547', u'BC556'),\n",
      " (u'BC547', u'BC556A')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "fps = list(fp)\n",
    "pprint(sorted(fps)[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "import os\n",
    "os.system('cp snorkel.db snorkel.db\\ candidates');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
